{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"H3THe9nVeLin"},"source":["# Exercise 1 : Locate the hidden fortress of the evil Dr. Unstructured"]},{"cell_type":"markdown","metadata":{"id":"4KgxV89GJVtb"},"source":["General guidelines : after decomposing each step into small tasks, for each task check if :\n","\n","\n","*   You know how to implement it : write the code\n","*   You dont know how to implement it : search google for either **code examples** or **existing packages**\n","\n","If you can't find the code for a simple task on google, it means it is not general enough yet, and you need to divide it into smaller tasks.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Gbq3EcicxXus"},"source":["### Step 1 : First, we need to make sure all agents are ready for duty.\n","Write a code that will print for each agent, that he is ready for duty.\n","For example for agent Fluffinson it would print 'Fluffinson, ready for duty!'\n","\n","> Use a **loop** and a **f-string**"]},{"cell_type":"code","metadata":{"id":"ujuy1DMR14gv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b8a31c10-b5dc-455b-ef48-1946013b4085"},"source":["# Code printing ready for duty messages\n","agents = ['Doggson', 'Fluffinson', 'Marshmallow', 'Bella']\n","\n","# Write your code here :\n","for agent in agents:\n","  print(f'{agent}, ready for duty!')\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Doggson, ready for duty!\n","Fluffinson, ready for duty!\n","Marshmallow, ready for duty!\n","Bella, ready for duty!\n"]}]},{"cell_type":"markdown","metadata":{"id":"om85Hlr7y31R"},"source":["### Step 2 : Now that our agents are ready for duty, they are hungry.\n","We need a way to retrieve their favorite food. Write a function that takes the name of an agent as argument, and returns their favorite food. Don't forget to use **types** and **documentation**.\n","Here are the favorite foods of the different agents. Please keep them secret.\n","\n","*   Doggson: Chicken\n","*   Fluffinson: Milk\n","*   Bella: Apples\n","\n"]},{"cell_type":"code","metadata":{"id":"gZHLQxAry2jw"},"source":["# Write your code here :\n","def get_favorite_food(name:str) -> str:\n","  \"\"\"\n","  Returns the favorite food of an agent\n","  \"\"\"\n","  favorite_foods = {'Doggson':'Chicken', 'Fluffinson':'Milk', 'Bella':'Apples'}\n","  return favorite_foods[name]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zj5WmuaM0q_M"},"source":["Now use this function to print the favorite food of Bella. It should print : 'The favorite food of Bella is Apples'. Use a **function call** and an **f-string**."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ObQmOOJ00v4E","outputId":"d409e7a0-1de3-49b4-f7ec-f4b17c68ec17"},"source":["# Call your function here:\n","food = get_favorite_food('Bella')\n","print(f'The favorite food of Bella is {food}')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The favorite food of Bella is Apples\n"]}]},{"cell_type":"markdown","metadata":{"id":"3qRqcbJe1qdR"},"source":["### Step 3 : Quick, our agents just intercepted a new code message sent from the hidden fortress of the evil Dr. Unstructured !\n","Our top communication experts tell us that the longest word from that message contains a crucial clue to the location of the fortress. We need your help to **print** the **longest** **word** from that message.\n","\n","Here is the secret message :\n","\n","> We are guarding the hidden fortress where it is snowing and we are so cold\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L8Suw6-h2nFU","outputId":"c61b8266-b716-4847-b538-bc7c107ab00c"},"source":["# Write your code here:\n","message = 'We are guarding the hidden fortress where it is snowing and we are so cold'\n","words = message.split(' ')\n","longest_word = ''\n","for word in words:\n","  if len(word) > len(longest_word):\n","    longest_word = word\n","print(longest_word)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["guarding\n"]}]},{"cell_type":"markdown","metadata":{"id":"bVLXo5RWRb2p"},"source":["### Step 4 : eutils is an API provided by PubMed. It allows to search and retrieve biomedical publications.\n","You can get the number of publications matching a particular query, by supplying the query for the term parameter in the URL.\n","\n","For example: https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term=guarding&retmax=0&retmode=json\n","\n","\n","\n","1.   Use this URL in your browser to see the structure of the JSON response it returns. Notice how dictionaries and lists in JSON look similar to dictionaries and lists in python.\n","2.   What do you think is the search query in this URL ? Try different search queries.\n","3.   Write a function in python that takes as parameter a query (or search term) and returns the number of publications matching this query in PubMed.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"u1b-10ix4B1-"},"source":["import requests\n","# Write your code here :\n","def get_publications_count(query:str) -> int:\n","  url = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term={query}&retmax=0&retmode=json'\n","  result = requests.get(url)\n","  if result.status_code == 200:\n","      return result.json()['esearchresult']['count']\n","  else:\n","      print('Can not access the URL')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AqjF9mtnT42v"},"source":["Now, use this function to retrieve and **print** the number of publications corresponding to the term **guarding**."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CPogQ22W2mym","outputId":"aacbbe3a-5d9a-432a-ce2c-76388320174d"},"source":["# Write your code here :\n","print(get_publications_count('guarding'))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["23656\n"]}]},{"cell_type":"markdown","metadata":{"id":"GoU0WIYW2O69"},"source":["### Step 5 : Now, sum together all the digits of the number.\n","\n","For example if the number of publications was 123 you should get 1 + 2 +3  = 6\n","\n","**TIP 1**: A string is a sequence. You can **loop** over it like you can loop over a list.\n","\n","**TIP 2**: You can cast variables to change their type. For example you can cast an integer into a string, so it will behave like a string. And you can cast a string into an integer.\n","\n","- *my_integer=int('6')*\n","- *my_string = str(234)*\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bwzDDPx9ha0s","outputId":"125bed10-d316-4865-d6f1-1f6cc3852186"},"source":["# Write your code here :\n","sum = 0\n","pub_count = get_publications_count('guarding')\n","s_pub_count = str(pub_count)\n","for s_digit in s_pub_count:\n","  sum += int(s_digit)\n","print(sum)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["22\n"]}]},{"cell_type":"markdown","metadata":{"id":"bLPMLvkK30SJ"},"source":["### Step 6 : Good job! We now have the first coordinate of the secret fortress of the evil Dr. Unstructured.\n","Our agents are ready. Now you need to find the second coordinate. Thankfully, agent Mittenson, after he finished playing with the curtains, intercepted another transmission from the evil agents for the Dr. Unstructured. The transmission was just a list of numbers. However, our best data experts think that the only number not divisible by **2** is the second coordinate of the hidden fortress.\n","\n","Agent Doggson has charged you personally with uncovering (**printing**) that second coordinate. Here are the intercepted numbers :\n","\n","\n","\n","> 8, 6, 10, 11, 14, 2\n","\n","TIP : You will need to search on google about the **modulo** operator in python\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NsdBlMYc7zAS","outputId":"e54add78-3022-46c3-8ac7-4086f932f1fb"},"source":["# Write your code here :\n","numbers = [8, 6, 10, 11, 14, 2]\n","for number in numbers:\n","  rest = number % 2\n","  if rest != 0:\n","    print(number)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["11\n"]}]},{"cell_type":"markdown","metadata":{"id":"dL0da-VHkfuK"},"source":["# Exercice 2 : Let's build our own search engine !"]},{"cell_type":"markdown","metadata":{"id":"wVQOiU0tdcc5"},"source":["In this exercice we will build our own database, add publications from PubMed, and search them using stopwords and lemmatization.\n","\n","We will also calculate the score of each match and rank the hits by score."]},{"cell_type":"markdown","metadata":{"id":"wBb3cJjzG5PP"},"source":["What we want is to be able to index text such as 'dogs are cool\" and be able to find it with a query such as 'are dogs cool ?'. This means that we need to index both our text and our query as words.\n","\n","### Step 1 : To do that, let's first design a function **get_words** that will take as input a string of text, and return a list of words.\n","\n","We dont want the returned words to contain punctuation or stopwords.\n","\n","TIP1: Use the function **word_tokenize** from the nltk package\n","\n","TIP2: You can check if a word is in **string.punctutation**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i6O633FXF7Ad","outputId":"2f5a58e2-ac73-4e22-cadc-b01a5aa14b42"},"source":["import string\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('punkt_tab') # Add this line to download the missing resource\n","\n","def get_words(text:str) -> list:\n","  \"\"\"\n","  Returns meaningful words from the text\n","  \"\"\"\n","  # Write your code here :\n","  words = nltk.word_tokenize(text)\n","  clean_words = []\n","  for word in words:\n","    if word not in stopwords.words('english'):\n","      if word not in string.punctuation:\n","        clean_words.append(word)\n","  return clean_words\n","\n","# Use print to try out your code here :\n","print(get_words('dogs are cool!'))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['dogs', 'cool']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]}]},{"cell_type":"markdown","metadata":{"id":"_wWcMVylI-DO"},"source":["### Step 2 : Now that we have a function that can transform any text into words, we want to build a database (implemented as dictionary).\n","The dictionary will **associate** each word with the index of the original text, stored in a separate **list**."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gGgDfKp7JPCK","outputId":"10255fe9-c297-40c9-97a0-3468ffbb9b58"},"source":["def build_database(texts:list) -> dict:\n","  \"\"\"\n","  Returns a dictionary associating each word of each text to the index of that text\n","  \"\"\"\n","  database = {}\n","  # Write your code here :\n","  for index, text in enumerate(texts):\n","    words = get_words(text)\n","    for word in words:\n","        if word not in database:\n","          database[word] = set()\n","        database[word].add(index)\n","  return database\n","\n","# Try your code with a print here :\n","print(build_database(['dogs are cool!', 'my computer is too slow.']))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'dogs': {0}, 'cool': {0}, 'computer': {1}, 'slow': {1}}\n"]}]},{"cell_type":"markdown","metadata":{"id":"u56VHRR8NQka"},"source":["### Step 3 : Now let's create the function **get_match_indexes** that will take the database and a query string as input, and return the indexes of all mathing texts"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pcdYo839Naor","outputId":"93e1b42e-961c-4951-88f6-1ee436fc9d66"},"source":["def get_match_indexes(database:dict, query:str) -> list:\n","  \"\"\"\n","  Returns the indexes of sentences matching the query\n","  \"\"\"\n","  match_indexes = set()\n","  # Write your code here :\n","  query_words = get_words(query)\n","  for word in query_words:\n","    if word in database:\n","      word_match_indexes = database[word]\n","      match_indexes.update(word_match_indexes)\n","  return match_indexes\n","\n","# Let's try this function :\n","demo_database = build_database(['dogs are cool!', 'my computer is too slow.'])\n","print(get_match_indexes(demo_database, 'I like dogs'))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{0}\n"]}]},{"cell_type":"markdown","metadata":{"id":"F_0sjMACPJ0L"},"source":["### Our search engine is ready !\n","Lets combine the functions we created. We will add two sentences to the database, then search it with a query :"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8rKnKJM_PT_n","outputId":"7826006e-54a3-4070-a6c8-ea0f97f3a57f"},"source":["texts = ['dogs are cool!', 'my computer is too slow.']\n","demo_database = build_database(texts)\n","for match_index in get_match_indexes(demo_database, 'I like dogs'):\n","  print(texts[match_index])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dogs are cool!\n"]}]},{"cell_type":"markdown","metadata":{"id":"K6yufHMWHWRa"},"source":["### Step 4 : Nice job! You now have a fully functional search engine.\n","But before we can index some cool stuff, such as publications from PubMed, we need to improve it a little.\n","\n","For example, let's try to search for 'My dog is great!'. How many matches do we have ? Why ?"]},{"cell_type":"code","metadata":{"id":"f6DCCEEXHblD"},"source":["# Write here the code to search for 'My dog is great!'\n","for match_index in get_match_indexes(demo_database, 'My dog is great!'):\n","  print(texts[match_index])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GkYm9QspUIgZ"},"source":["### Step 5 : It seems that our search engine doesnt know that dogs is the plural of dog.\n","The simplest way to deal with that, is to transform each word into a root form, that we will store in our database.\n","\n","\n","> For example, we want to transform \"dogs\" into \"dog\"\n","\n","\n","And for that we can use lemmatization.\n","\n","Let's improve our **get_words** method by lemmatizing each word"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pqy7ysmt82kP","outputId":"d89328e3-05ec-4564-d35d-31aef68ea778"},"source":["import string\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","\n","lemmatizer = WordNetLemmatizer()\n","\n","def get_words(text:str) -> list:\n","  \"\"\"\n","  Returns meaningful words from the text\n","  \"\"\"\n","  # Write your code here :\n","  words = nltk.word_tokenize(text)\n","  clean_words = []\n","  for word in words:\n","    if word not in stopwords.words('english'):\n","      if word not in string.punctuation:\n","        word = lemmatizer.lemmatize(word)\n","        clean_words.append(word)\n","  return clean_words\n","\n","# Let's try the function here :\n","print(get_words('the dogs are outside'))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["['dog', 'outside']\n"]}]},{"cell_type":"markdown","metadata":{"id":"K6eUb__iIi5e"},"source":[" What if we try the text 'My Dogs are great' ?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rke2ayWhIjy_","outputId":"4bcffd9d-f2ec-49ee-d11e-1278d2a6df64"},"source":["# Write here the code to search for 'My dog is great!'\n","print(get_words('My Dogs are great'))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['My', 'Dogs', 'great']\n"]}]},{"cell_type":"markdown","metadata":{"id":"e5mbzA0xBvom"},"source":["### Step 6 : Update the function **get_words** to make sure we only add the the database words in lowercase form."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bU99mqZ_Bww3","outputId":"bc065c3f-96a2-425d-8b61-8cc2f19c9c5f"},"source":["import string\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","\n","nltk.download('wordnet')\n","\n","lemmatizer = WordNetLemmatizer()\n","\n","def get_words(text:str) -> list:\n","  \"\"\"\n","  Returns meaningful words from the text\n","  \"\"\"\n","  text = text.lower()\n","  words = nltk.word_tokenize(text)\n","  clean_words = []\n","  for word in words:\n","    if word not in stopwords.words('english'):\n","      if word not in string.punctuation:\n","        word = lemmatizer.lemmatize(word)\n","        clean_words.append(word)\n","  return clean_words\n","\n","print(get_words('The Dogs are outside'))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['dog', 'outside']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"markdown","metadata":{"id":"X-dJJJ099rjr"},"source":["### Step 7 : What if we add to our database two sentences :\n","\n","\n","*   I like dogs\n","*   Dogs and cats\n","\n","If we search for '**I like my Dog**', the first sentence is clearly a better match than the second. So we should display it first.\n","\n","This means that we should **rank** our matches based on the *number of words from the query that they contain*.\n","\n","Modify the **get_match_indexes** function to store the number of words from the query matched for each document where there was a match.\n","\n"]},{"cell_type":"code","metadata":{"id":"Y9MLuJ1s-p3t","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5a234e3d-73ac-4cc8-c696-1f7cb1135ac4"},"source":["from collections import defaultdict\n","\n","def get_match_indexes(database:dict, query:str) -> dict:\n","  \"\"\"\n","  Returns the indexes of sentences matching the query\n","  \"\"\"\n","  match_indexes = defaultdict(int)\n","  # Write your code here :\n","  query_words = get_words(query)\n","  for word in query_words:\n","    if word in database:\n","      word_match_indexes = database[word]\n","      for word_match_index in word_match_indexes:\n","        match_indexes[word_match_index] += 1\n","  return match_indexes\n","\n","# Now let's try this code :\n","texts = ['Dogs and cats', 'I like dogs']\n","demo_database = build_database(texts)\n","print(get_match_indexes(demo_database, 'I like my Dog'))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["defaultdict(<class 'int'>, {1: 2, 0: 1})\n"]}]},{"cell_type":"markdown","metadata":{"id":"MHNBkGQUEH1i"},"source":["### Step 8 : And add a **get_ranked_matches** function to rank match indexes based on the number of word from the query a sentence in our database matches."]},{"cell_type":"code","metadata":{"id":"-oqVFuAIEIQ9"},"source":["def get_ranked_matches(matches:dict)->list:\n","  \"\"\"\n","  Returns a ranked list of matches\n","  \"\"\"\n","  # Write your code here :\n","  l_matches = [(index, score) for index, score in matches.items()]\n","  sorted_matches = sorted(l_matches, key=lambda m:m[1], reverse=True)\n","  return [m[0] for m in sorted_matches]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"scCQuqVbACZg"},"source":["Now let's try it on an example :"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0j0mpDfAAE3w","outputId":"09146c78-9507-4e6e-c1af-3b2bf92e24d4"},"source":["texts = ['Dogs and cats', 'I like dogs']\n","demo_database = build_database(texts)\n","matches = get_match_indexes(demo_database, 'I like my Dog')\n","ranked_matches = get_ranked_matches(matches)\n","\n","for match_index in ranked_matches:\n","  print(texts[match_index])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["I like dogs\n","Dogs and cats\n"]}]},{"cell_type":"markdown","metadata":{"id":"_cGOfDRW_eun"},"source":["### Step 9 : Now, lets nicely pack all this functionality inside a **class** called **SearchEngine**"]},{"cell_type":"code","metadata":{"id":"BM_XF0UO_iDg","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cb2f8f78-a163-4dd5-bb5c-94ecfbc5e0b5"},"source":["import string\n","import nltk\n","from collections import defaultdict\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","\n","class SearchEngine:\n","\n","  def __init__(self):\n","    self.lemmatizer = WordNetLemmatizer()\n","\n","  # Add your functions after this line. Don't forget to transform them into methods. (the first parameter must be 'self')\n","\n","  def get_words(self, text:str) -> list:\n","    text = text.lower()\n","    words = nltk.word_tokenize(text)\n","    clean_words = []\n","    for word in words:\n","      if word not in stopwords.words('english'):\n","        if word not in string.punctuation:\n","          word = self.lemmatizer.lemmatize(word)\n","          clean_words.append(word)\n","    return clean_words\n","\n","  def build_database(self, texts:list) -> dict:\n","    self.texts = texts\n","    self.database = {}\n","    for index, text in enumerate(texts):\n","      words = self.get_words(text)\n","      for word in words:\n","          if word not in self.database:\n","            self.database[word] = set()\n","          self.database[word].add(index)\n","\n","  def get_match_indexes(self, query:str) -> dict:\n","    match_indexes = defaultdict(int)\n","    query_words = self.get_words(query)\n","    for word in query_words:\n","      if word in self.database:\n","        word_match_indexes = self.database[word]\n","        for word_match_index in word_match_indexes:\n","          match_indexes[word_match_index] += 1\n","    return match_indexes\n","\n","  def get_ranked_matches(self, matches:dict)->list:\n","    l_matches = [(index, score) for index, score in matches.items()]\n","    sorted_matches = sorted(l_matches, key=lambda m:m[1], reverse=True)\n","    return [m[0] for m in sorted_matches]\n","\n","  def search(self, query:str) -> None:\n","    match_indexes = self.get_match_indexes(query)\n","    ranked_matches = self.get_ranked_matches(match_indexes)\n","    for match_index in ranked_matches:\n","      match_text = self.texts[match_index]\n","      print(match_text)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"markdown","metadata":{"id":"VQBQ9LICKcfU"},"source":["Now let's try this new class :"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oU9PR4zgGdT_","outputId":"0d6da347-facf-4fb9-a884-5df6c069ffc9"},"source":["engine = SearchEngine()\n","engine.build_database(['Dogs and cats', 'I like dogs', 'only cats here'])\n","engine.search('I like my dog')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["I like dogs\n","Dogs and cats\n"]}]},{"cell_type":"markdown","metadata":{"id":"QMq2QOiCHBZp"},"source":["### Step 10 : Now let's try with some actual publication titles !\n","Write a function that will retrieve a list of titles from LitCovid API"]},{"cell_type":"code","metadata":{"id":"OyCumCWjHFPb"},"source":["import requests\n","def get_publication_titles() -> int:\n","  \"\"\"\n","  Returns the top 100 most recent titles from publications in LitCovid\n","  \"\"\"\n","  url = f'https://www.ncbi.nlm.nih.gov/research/coronavirus-api/latest/?limit=100'\n","  # Write your code here :\n","  result = requests.get(url)\n","  if result.status_code == 200:\n","    titles = []\n","    for p in result.json():\n","      titles.append(p['title'])\n","    return titles\n","  else:\n","      print('Can not access the URL')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XoogNBLa7UVl"},"source":["Now let's try it !"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1LXu37pOIPnS","outputId":"c4a159a1-29db-4089-c87c-89b59a05faab"},"source":["titles = get_publication_titles()\n","engine = SearchEngine()\n","engine.build_database(titles)\n","engine.search('vaccine covid-19')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Analysis of antibody markers as immune correlates of risk of severe COVID-19 in the PREVENT-19 efficacy trial of the NVX-CoV2373 recombinant protein vaccine.\n","Daily briefing: People with cancer lived longer if they'd had a COVID-19 vaccine.\n","Nationwide estimates of SARS-CoV-2 infection fatality rates and numbers needed to vaccinate for COVID-19 vaccines in 2024 in Austria.\n","Nanobody-based combination vaccine using licensed protein nanoparticles protects animals against respiratory and viral infections.\n","mRNA covid vaccines may \"turbo charge\" cancer immunotherapy, research suggests.\n","Science for vaccine policy: Independent review of the September 2025 ACIP processes, deliberations and votes.\n","Evolving Features of Acute Flaccid Myelitis After COVID-19: A Four-Case Series.\n","Loans dominated COVID-19 funding: it's time to adjust.\n","Retrospective Analysis on Mortality and Functional Outcomes in Critically Ill Elderly with COVID-19: A Comparative Study Between Full Code and DNR Orders.\n","Frailty Assessment and Outcomes During a COVID-19 Outbreak in a Long-Term Care Facility: The FRAIL-LTCF Scale.\n","Long-term consequences of mental health distress during the COVID-19 pandemic on subjective memory decline: findings of the PAMPA cohort.\n","Risk of anxiety disorders and insomnia following COVID-19 vaccination.\n","Internet use and subjective well-being among older Chinese: Evidence from repeated cross-sections before and after COVID-19 (CGSS 2017-2023).\n","COVID-19 mortality among people living with HIV/AIDS in Brazil: a multilevel analysis.\n","Impact of COVID-19 pandemic on Legionella testing and infection rates in Ontario.\n","Effectiveness of spring 2024 (XBB.1.5) and autumn 2024 (JN.1) COVID-19 vaccination against hospitalisation in England.\n","Pre-existing comorbidities and hospitalization for COVID-19 are associated with post-COVID conditions in the U.S. veteran population.\n","Back to school: a qualitative study evaluating a community-informed COVID-19 risk communication intervention for rural elementary school children and their families.\n","Vitamin D Pathway as a Multi-Level Predictor of COVID-19 Severity and Mortality: Integrating Serum Levels, FokI (rs2228570) VDR Polymorphism, and Lung Tissue Expression.\n","Postpartum pulmonary micronodules and thyroid cystic nodules in a COVID-19 vaccinated patient: A CARE-compliant case report.\n","Prediction of mortality in cancer patients with COVID-19 using machine learning methods.\n","China's COVID-19 aid in Africa: trends and implications for future pandemic preparedness.\n","Cardiac manifestations in children and adolescents diagnosed with pediatric multisystem inflammatory syndrome related to COVID-19.\n","Efficacy of Lactococcus lactis Strain Plasma in Patients with Mild COVID-19: A Multicenter, Double-Blinded, Randomized-Controlled Trial (PLATEAU Study).\n","Decoding Fibrosis in Non-Resolvable COVID-19: a role for myeloid-specific HIF1A deletion.\n","Factors affecting timeliness in vaccination of under-five children in India: A cross-sectional study using the NFHS 5 survey during COVID-19.\n","A response to the letter to the editor regarding \"The mean corpuscular volume (MCV) is a hematological biomarker associated with COVID-19 mortality risk\".\n","The continued impact of COVID-19 during the Omicron era on immunocompromised individuals in Japan.\n","Association between MASP2 gene polymorphisms and susceptibility to Covid-19 in Iranian patients: a case-control study.\n","Trying to create order in chaos-healthcare workers' perspective of COVID-19 intensive care (a qualitative study).\n","Challenges of high-quality clinical research in Colombia: an example of a clinical trial amidst the COVID-19 pandemic.\n","Female homicides in Brazil before and during the COVID-19 pandemic: an interrupted time-series analysis.\n","The Intensity of Adolescent Substance Use Before and After the COVID-19 Pandemic.\n","Impact of an asynchronous telerehabilitation program on the self-efficacy and motivation for physical activity in discharged COVID-19 patients: a secondary analysis of a randomized controlled trial.\n","Evaluation of SARS-CoV-2 Variants After the Declaration of End of COVID-19 Pandemic: BA.2.86 (Pirola) and EG.5 (Eris) Variants as Global Public Health Concerns.\n","COVID-19 infection and cancer regression: a review of current evidence, potential mechanisms, and clinical perspectives on a Paradoxical phenomenon.\n","Unraveled role of TLR7-mediated interferon signaling activation in COVID-19.\n","Rationally designed, ACE2 mimetic binder to the SARS Cov-2 associated Spike protein for COVID-19 therapeutics and beyond.\n","Subglottic Stenosis After COVID-19 Mimicking Bronchial Asthma, Treated by Bronchoscopic Resection.\n","Effectiveness of Nirmatrelvir/Ritonavir or Molnupiravir Use in Immunocompromised Patients on B-Cell-Depleting Therapy With COVID-19: A Target Trial Emulation Study.\n","In-hospital mortality predictors among COVID-19 patients in the West Bank, Palestine: a multi-center retrospective cohort study.\n","A Rare Case Report of COVID-19 and Leptospirosis Co-infection Triggering Acute Myocarditis.\n","IL-6, IFN-gamma, IL-17A elevations and glutathione depletion predict severe MODS and mortality in critically ill children with COVID-19 and bacterial sepsis: a prospective cohort study from the Brazilian Amazon.\n","Mechanical power is an early predictor of mortality in mechanically ventilated patients with COVID-19.\n","State Power and COVID-19 Vaccination Efforts.\n","Isolated orbital mucormycosis in the setting of COVID-19 pneumonia.\n","[Impact of legislative and care changes during the COVID-19 pandemic on access to the electronic medical records by family doctors. Longitudinal analysis from 2018 to 2023 of interrupted time series in a health care area].\n","Food insecurity risk and dietary habits of international students in the COVID-19 pandemic period.\n","Bobath Approach in Telemedicine Versus Conventional Treatment in Newborns Discharged from the NICU During the COVID-19 Pandemic.\n","Characteristics and Outcomes of Immunocompromised Patients With COVID-19 Infection Admitted to an Intensive Care Unit: A Retrospective Cohort Study.\n","Impact of COVID-19 on cervical cancer screening: A cohort study.\n","Surge in C-section deliveries during the COVID-19 pandemic: insights from a cross-sectional study in Gujarat, India.\n","Participation in multiple nutrition assistance programs early in the COVID-19 pandemic and dietary intake frequencies among WIC-participating children ages 1-4 years.\n"]}]}]}